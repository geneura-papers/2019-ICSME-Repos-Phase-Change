\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{url} 
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{svg}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Temporal Evolution In Commit Size Distribution\\
  \thanks{----} }

\author{\IEEEauthorblockN{Omitted for submission} \IEEEauthorblockA{-}
  \and \IEEEauthorblockN{Omitted for submission} \IEEEauthorblockA{-}
}

\maketitle

\begin{abstract}
  Software nowadays is almost exclusively developed using source
  control systems. Traditionally, the study of the evolution of this
  type of systems is usually done from the perspective of
  self-organized complex systems, since the version-control tools used
  allow a community-oriented development without a fixed or appointed
  leader. Understanding if and how a software development team
  self-organizes might give hints on how to improve productivity,
  reduce bugs or, in the case of open source systems based on
  volunteer woor, reduce churn and increase engagement.  However, one
  of the essential characteristics needed to understand this type of
  systems' behaviour and to know if we are truly dealing with an
  auto-organized community is the appearance or not of a power law in
  the events' size distributions.  In this case, we have chosen to
  treat commits as our events, that is, additions to the code by
  users.
  % - This is our choice and should be presented that way. Other
  % people might use a different thing, like file size, author
  % interactions or whatever - JJ
  But we have to be extremely cautious with this kind of approach,
  because the existence or not of this type of distributions should be
  always analyzed mathematically to minimize posible sources of bias.
  We will use the concept of hypothesis tests for that purpose, that
  is, checking what is the likelihood that our data follows a power
  law distribution instead of some other with similar characteristics.
  The conclusions of these tests may not shed light on whether we are
  in a state of self-organization.  Software development is a process
  that evolves over time and analysis at a specific moment is not
  significant.  Our approach in this work uses a temporal analysis
  over the evolution of commit's distribution in software
  projects. For that, we have selected a set of repositories that
  exhibit singular behaviors such as a large number of contributions
  versus few or inconclusive results in statistical tests.  Our study
  seeks to provide conclusive evidence about the state of the chosen
  repositories, answering wether they have not reached a state of
  self-organization in all its evolution (that is, never present power
  law distributions) or, if they have done so, but due to other code
  insertions and to the temporary nature of the creative process, this
  self-organized state has been altered.

  % Abstract don't normally have paragraph, and in this phse it should
  % have to be a bit shorter - JJ

\end{abstract}

\begin{IEEEkeywords}
  Complex systems, self-organizing systems, self-organized
  criticality, power laws, software development, software repositories
\end{IEEEkeywords}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{introduction}

The study of software evolution from the point of view of complex
systems yields new perspectives on how software teams evolve by
looking at their contributions in the source code repositories they
work with.

In most cases, and notably so in the case of open source repositories
with aportations of volunteer work, developers self-organize, with no
real central planning. This gives rise to certain patterns in the
sotware repository that can be observed and measured, mainly through
the measurement of the size of changes over the repositories of code.

This self-organization, lacking an ultimate objective, can make the
system evolve in different ways. It can lead to an ultimately ordered
system, with changes of similar size being done in lockstep by all
developers. This rarely happens however. Another situation is to
evolve into chaos: developers do any kind of change, at any time,
unrelated to other developers or overstepping work already done. This
happens with a certain frequency, and is not unheard of.

Finally, in some cases it reaches a critical state via
self-organization. In this state there can be feedback loops that make
the whole system more productive and in general any change in the
system can bring any amount of change later on, but the system is
prevented from going into chaos or into an ordered state, both quite
improductive. A critically self-organized system could be, in many
cases, a desired state since the feedback loops can be more rewarding
for developers, thus reducing churn and keeping (mostly volunteers)
developers being productive for the system.

Being self-organized, however, is not something that can be imposed,
by definition. Self-organizing systems can anyway be influenced by
entering several different mechanisms. That is why it's interesting,
from the software engineering point of view, to measure the state a
software development system is in.

One of the ways of knowing if the system is in that desired critical
state is finding power laws in the size of changes. These power laws,
however, are more elusive that were discovered at first sight, with
the mathematical precise establishment of that hypothesis being only
possible via a strict hypothesis testing. Besides, the critical state
is not a given, but established in a certain point in time.

The main objective of this paper is to establish whether a set of
chosen repositories follow a power law or, in precise statistical terms,
if their distribution of sizes is best described by a power law (as
compared with other statistical distributions), and if they do, in
what moment in time they started to follow it.

In order to do so, we follow the discrete step of commits as a
timeline, working with the number of lines changed in every commit. In
order to check the temporal evolution, we divide the commit timeline
in five parts, and check our hypotheses for every one of them. This
rigorous and principled hypothesis test procedure will allow us to
establish whether, or not, the chosen repositories are self-organized
or not. From the observation of the features of the repositories, we
will eventually reach some conclusions.

% --------------------------------------------------------

The rest of the papers is organized as follows: next section presents
the state of the art in the study of self-organized criticality in
repos. Our methodology is presented in Section
\ref{sec:method}. Results are later on presented in \ref{res}, and
finally we will outline our conclusions.

\section{State of the art}\label{soa}


% Taken from previous paper. It's not accepted yet and we can always
% improve it later on - JJ
The study of code repositories from the point of view of
self-organized criticality has not followed a continuous line of
investigation.

On the one hand, we find that self-organized criticality has been
Description of a wide variety of code repositories with a certain
probability. These studies can be found
in\cite{wu2007empirical,gorshenev2004punctuated}, but they are not the
only ones of this kind. Tests on the possible self-organized
criticality have also been sought in another type of repositories and
projects, which are enumerable in size and purpose
\cite{Merelo2016:repomining,merelo16:slash,merelo16:self,merelo2017self}.

In most of these studies, however, the evidences in favor of the
existence of a power law are not accompanied by a significant
statistical study. It is usual, as described in \cite{newman2005power}
that the evidence leading to a suggestion of a power law in the
distribution is visual. Once we have these tests, the study goes
through the adjustment of a possible powerlaw
\cite{merelo2017self,arafat2009commit}.

The general trend being the lack of statistical evidence that supports
the hypothesis of the existence of a power law, the truth is that as
described in \cite{newman2005power, clauset2009power} the most common
method for making subsequent adjustments, Leas Square Medium
\cite{merelo2017self,arafat2009commit,merelo16:self}, usually implies
the existence of a greater error than the possible alternatives.

Currently, the general trend that started with the description of the
power laws in self-organized systems has been slowed down. Instead,
due to the existence of more objective evaluation methods, the results
that were assumed until now are being re-evaluated.

Examples of this trend are papers such as \cite{Holme2019,
  Broido2019}, where the power laws in the networks and in the results
have been reevaluated, obtaining an analysis that can change the way
we make our assumptions about power laws.

Next we will present the methodology used to choose those repositories
and mine their information.


% --------------------------------------------------------


\section{Methodology}
\label{sec:method}

In this section we are going to explain the methods used in our
research.

Our methodology hinges on four distinguished parts of our workflow.
First of all, we highlight the process of data extraction, which
follows particular considerations within the usual study of
repositories. Later we talk about the mathematics behind our
approaches to understand the distribution behind the data, which leads
to the third part, where we collect the information obtained in the
previous one and explain how it has been classified. Finally we added
a section of visualization to briefly explain some changes that can be
disconcerting when it comes to visualizing possible power laws.


\subsection{Data extraction and division}
%% rewrite
We have chosen 5 repositories in different states of development.
These repositories were chosen in \cite{Merelo2016:repomining}, for
several reasons: They all represent a wide array of languages and
functionalities, from web frameworks such as Django to Atom plugins,
through one-of-a-kind frameworks such as Docker.

Normally a code repository is related to a software project, for this
reason, it is usual that they include several different languages
which are used in different parts of the project.  This mixture of
languages also offer a big range of variability between languages that
are interpreted or compiled, either to machine code or to bytecode.

Repositories vary also in {\em professionalism}, that is, the team
behind that software project. From a small Atom editor plugin to
TensorFlow, an open library created and maintained by a fully
professional community.

Repository mining was done during the months of January to March 2017,
with the second sweep of the same repositories performed in February
2019.

The way we look at changes in the repository was initially proposed by
\cite{Merelo2016:repomining} and was also used in
\cite{merelo2017self}, where a deeper explanation can be found.


This procedure is based on three main concepts:
\begin{itemize}
\item The usage of a discrete timeline formed by the commits, with
  every commit counting as time=1.
\item Work with selected files in the repository, excluding those
  related to images or style
\item We take the largest value from the inserted and deleted lines of
  code.
\end{itemize}

%% New
Since we want to understand how commits distribution evolve, we
decided to divided each dataset into 5 different sections, each of
them of equal size. These division are made in the commit order and
represent progressive temporal windows in a evolving system like these
repositories.

With those divisions made we generate 5 different datasets, each one
contains its corresponding section and all the previous ones, which
means we analyze all the information until the final commit of the
section.  These hopefully provide us a sigth in the evolution in time
of the commits distribution.


\subsection{Hypothesis tests}

Once those datasets are extracted, we begin to check the probability
of finding powerlaw or similar heavy-tailed distributions in the
dataset.

First of all we could test that checks whether the observed data set
actually follows a power-law, instead of only visualize the result.
This kind of tests can vary based on different measured and
techniques. The most popular one is presented in
\cite{clauset2009power}, which consists in using a goodness-of-fit
hypothesis test via bootstrapping procedure.

Up to this point, we have detected what data sets are unlikely to be
fitted by a power law in any of its range. Notice, on the contrary
case, that we are only assuming that we can not discard that a power
law is generating the data.  However, as there is some probability of
the appearance of this distribution in our data we can study and
analyze how its two main parameters may evolve between 2017 and 2019.

As it is unrealistic to think that a power law distribution will fit
all our data, our first step is to check what portion of the data
could be fitted with a power law, or in other words, what is the
minimal value (if there is one) from which the scaling relationship of
the power law begins \footnote{This is a fair assumption since we are
  working with heavy-tailed distributions and our main interest is the
  behaviour of the tail of our data.}.  This value is usually noted by
$x_{min}$ and is our first parameter.

Once we have the first value, we proceed to estimate the scale of our
power law.  As it is shown in papers like \cite{newman2005power,
  clauset2009power}, least square method is a poor but wide-spreaded
way to proceed when estimating the scale parameter. Instead, we are
going to use a direct method describe in \cite{clauset2009power} and
implemented in \cite{alstott2014powerlaw} that use the data values we
have. This method is known to produce a very nice fit with less error
than the others mentioned above.

Up to this point we have revisited our way of analyze power law
fitting and the estimation of our parameters. However, there is a more
deep question unanswered: does our data really follow (in a
statistically relevant way) a power law?  This kind of answers were
lacking in studies like \cite{merelo2017self} and they are relevant independently
our first test's results, since they usually offer an unbiased look of
the data .

Taking into account that our main question is wether a power law is
the best description of our data, we choose to apply a comparative
test that could evaluate if there are any alternative distribution
that could have generated our data with greater likelihood than a
power law. That is the main reason why we choose to use a
log-likelihood ratio test implemented in \cite{alstott2014powerlaw}.
There are two algorithm's outcomes. First we have the log-likelihood
ratio between the two candidate distributions. The sign of this
quantity will point out which distribution is more likely to be
producing out data. After it, we calculate the signification of this
ratio, a P-value. Following \cite{alstott2014powerlaw} indications we
establish our P-value threshold at $p=0.05$; above that point the
loglikehood ratio has no significance and we can not decide which
distribution is better fitting out data.

\subsection{Classification}

Since we are trying to uncover any variation we have decide to
summarize all the tests in a single statement, and see if it
changes. We use the scale proposed in \cite{clauset2009power}, which
is described as:
\begin{itemize}
\item \textbf{None}: Data-set is probably not distributed by a power
  law (first test failed).
\item \textbf{Moderate}: Power law is a possible fit but there are
  other plausible distributions that fit the data.
\item \textbf{Good}: Power law is a possible fit and none of the other
  distributions is plausible.
\item \textbf{Truncated}: when truncated power law is clearly favored
  over a simple power law
\end{itemize}

A relevant remark should be made: These scale clearly can obscure out
conclusions.  Maybe a more refined scale can expose slightly smaller
changes and split two equal classification (made with the scale
presented ) in two different categories.

\subsection{Visualization}
 
For the graphics included we should specify that we are going to use
the probability density function (PDF) in our plots. Due to the
requirement of binning the data to this type of graphic, we are going
to use a logarithmic spacing, since it reduces the statistical errors
in the tail in log-log plots at it is stated in
\cite{newman2005power}.

We also add Poisson distribution in the plots as an visual explanation
on why we do not make any hypothesis test with this kind of
distribution even though is a common example of heavy-tailed
distribution.



% --------------------------------------------------------


\section{Results}
\label{res}
In this section we present all the results obtained in our numerical
experiments.

On one hand we offer all the visualizations of all the temporal
sections made in the repositories. A pure example of these slices and how they evolve in the case of Mojo's repository can be found
in \ref{fig:mojoev}.

Moreover we have drawn 5 global plots that show  a visual distribution of the changes till the last commit of the section, and, next to these, a PDF plot of the distribution in a log/log scale with different
distribution adjusted. We have applied the same procedure in all repositories:Fig \ref{fig:cask}, \ref{fig:mojo}, \ref{fig:rakudo}, \ref{fig:django}, \ref{fig:tty}.

In addition, we have summarized in several tables the evolution of the
hypothesis tests performed comparing the distributions with the power
law. We add to these tables the information of the tests on the
likelihood of having a distribution of power law in order to give a
final grade according to the predefined scale: TABLE \ref{tab:2019testscask}, \ref{tab:2019testsdjango}, \ref{tab:2019testsmojo}, \ref{tab:2019testsrakudo}, \ref{tab:2019teststty}.



\begin{figure*}[htbp]
  \centerline{\includegraphics[width=0.95\textwidth]{img/mojo_temporal.eps}}
  \caption{Evolution in temporal windows of Commit size vs. Commit
    number in mojo's repository.}
  \label{fig:mojoev}
\end{figure*}

\begin{figure*}[htbp]
  \centerline{\includegraphics[width=0.95\textwidth]{img/adjusted_dist_cask.png}}
  \caption{2-column plot fom cask repository. On the right side an
    simple plot with the number of lines changed in every commit in
    front of commit's number is presented. For this particular
    temporal segment we plot the PDF plot of it, presenting possible
    distributions fits: Red,power laws; Blue, Log Normal; Green:
    Poisson}
  \label{fig:cask}
\end{figure*}

     
\begin{figure*}[htbp]
  \centerline{\includegraphics[width=0.95\textwidth]{img/mojo_global_estimation.eps}}
  \caption{2-column plot fom mojo repository. On the right side an
    simple plot with the number of lines changed in every commit in
    front of commit's number is presented. For this particular
    temporal segment we plot the PDF plot of it, presenting possible
    distributions fits: Red,power laws; Blue, Log Normal; Green:
    Poisson}
  \label{fig:mojo}
\end{figure*}


\begin{figure*}[htbp]
  \centerline{\includegraphics[width=0.95\textwidth]{img/tty_global.eps}}
  \caption{2-column plot fom tty repository. On the right side an
    simple plot with the number of lines changed in every commit in
    front of commit's number is presented. For this particular
    temporal segment we plot the PDF plot of it, presenting possible
    distributions fits: Red,power laws; Blue, Log Normal; Green:
    Poisson}
  \label{fig:tty}
\end{figure*}

\begin{figure*}[htbp]
  \centerline{\includegraphics[width=0.95\textwidth]{img/rakudo_global_plot.eps}}
  \caption{2-column plot fom rakudo repository. On the right side an
    simple plot with the number of lines changed in every commit in
    front of commit's number is presented. For this particular
    temporal segment we plot the PDF plot of it, presenting possible
    distributions fits: Red,power laws; Blue, Log Normal; Green:
    Poisson}
  \label{fig:rakudo}
\end{figure*}

\begin{figure*}[htbp]
  \centerline{\includegraphics[width=0.95\textwidth]{img/django_global_set.eps}}
  \caption{2-column plot fom Django repository. On the right side an
    simple plot with the number of lines changed in every commit in
    front of commit's number is presented. For this particular
    temporal segment we plot the PDF plot of it, presenting possible
    distributions fits: Red,power laws; Blue, Log Normal; Green:
    Poisson }
  \label{fig:django}
\end{figure*}


\begin{table*}[h!tbp]
  \caption{Cask summary results}
  \begin{center}
    \begin{tabular}{| p{0.12\linewidth} | p{0.08\linewidth} | p{0.08\linewidth} |
        p{0.08\linewidth} | p{0.1\linewidth} | p{0.1\linewidth}
         |}
      \hline
      Commit range & PL test&PL vs. LogN & PL vs. Exp & PL vs. PLtrunc & Result \\
      \hline
      Commit range 1 & 0.53& LogN & PL  & PLtrunc & Moderate \\
      Commit range 2& 0.078&ND & PL  & ND & Moderate \\
      Commit range 3& 0.208&ND  &  PL & ND & Moderate \\
      Commit range 4& 0.086&ND & PL  & ND & Moderate \\
      \hline

      \hline
    \end{tabular}
  \end{center}
  \label{tab:2019testscask}
\end{table*}

\begin{table*}[h!tbp]
  \caption{Django summary results}
  \begin{center}
    \begin{tabular}{| p{0.12\linewidth} | p{0.08\linewidth} | p{0.08\linewidth} |
        p{0.08\linewidth} | p{0.1\linewidth} | p{0.1\linewidth}
         |}
      \hline
      Commit range & PL test & PL vs. LogN & PL vs. Exp & PL vs. PLtrunc & Result \\
      \hline
      Commit range 1 & 0.0&  LogN & PL  &PLtrunc &  None\\
      Commit range 2 & 0.118& LogN & PL  &PLtrunc & Truncated \\
      Commit range 3 &  0.212&LogN & PL  &PLtrunc & Truncated \\
      Commit range 4 &  0.208&LogN & PL  &PLtrunc & Truncated \\
      \hline

      \hline
    \end{tabular}
  \end{center}
  \label{tab:2019testsdjango}
\end{table*}


\begin{table*}[h!tbp]
  \caption{Rakudo summary results}
  \begin{center}
    \begin{tabular}{| p{0.12\linewidth} | p{0.08\linewidth} | p{0.08\linewidth} |
        p{0.08\linewidth} | p{0.1\linewidth} | p{0.1\linewidth}
       |}
      \hline
      Commit range & PL test & PL vs. LogN & PL vs. Exp & PL vs. PLtrunc & Result \\
      \hline
      Commit range 1 & 0.0 & LogN & PL  &PLtrunc & None \\
      Commit range 2&  0.0& LogN & PL  &PLtrunc & None \\
      Commit range 3&  0.0& LogN & PL  &PLtrunc & None \\
      Commit range 4& 0.0  &  LogN & PL  &PLtrunc & None \\
      \hline

      \hline
    \end{tabular}
  \end{center}
  \label{tab:2019testsrakudo}
\end{table*}


\begin{table*}[h!tbp]
  \caption{Mojo summary results}
  \begin{center}
    \begin{tabular}{| p{0.12\linewidth} | p{0.08\linewidth}  | p{0.08\linewidth} |
        p{0.08\linewidth} | p{0.1\linewidth} | p{0.1\linewidth}
       |}
      \hline
      Commit range & PL test &PL vs. LogN & PL vs. Exp & PL vs. PLtrunc & Result \\
      \hline
      Commit range 1 & 0.21& ND & PL  & ND & Moderate \\
      Commit range 2& 0.202& ND & PL  & ND & Moderate \\
      Commit range 3& 0.37& ND  &  PL & ND & Moderate \\
      Commit range 4&0.566 & ND & PL  & ND & Moderate \\
      \hline

      \hline
    \end{tabular}
  \end{center}
  \label{tab:2019testsmojo}
\end{table*}


\begin{table*}[h!tbp]
  \caption{tty summary results}
  \begin{center}
    \begin{tabular}{| p{0.12\linewidth} | p{0.08\linewidth} | p{0.08\linewidth} |
        p{0.08\linewidth} | p{0.1\linewidth} | p{0.1\linewidth}|}
      \hline
      Commit range & PL test &PL vs. LogN & PL vs. Exp & PL vs. PLtrunc & Result \\
      \hline
      Commit range 1 &0.08 &ND & ND  & PLtrunc & Moderate \\
      Commit range 2& 0.0&ND & PL  & ND & None \\
      Commit range 3& 0.0&ND  &  PL & ND & None \\
      Commit range 4& 0.0&ND & PL  & ND & None \\
      \hline

      \hline
    \end{tabular}
  \end{center}
  \label{tab:2019teststty}
\end{table*}

% --------------------------------------------------------


\section{Conclusions}\label{conc}
Summarizing, our work shows no visible change in the commit distribution. We can address this 
absence of changes to several factors, but we would like to emphasize two of them: Scale proposed and temporal windows. 

Talking about scale, as it was stated, the small act of choosing one alter or bias our results. As a further development, different scale should be used in this classification, or, if necessary, a new one, with extra details should be created. 

In addition, temporal windows could have been selected in a better way. In most repositories there is some kind of evidence that a power law could be found. This indicates that we have surpassed the initial states were self organization may have not existed. A deeper and more granulated analysis should be made in order to understand the beginning of self organization behaviour. More over as the system could regulate himself, we should reevaluate possible configuration of temporal windows to check if the speed of self-organization don't let us see temporal distribution changes

\section{Acknowledgements}
\textit{Omitted for submission }

\bibliographystyle{apalike} 
\bibliography{biblio,geneura}

\end{document}
